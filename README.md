# Jigsaw Toxic Comment Classification
 Identify and classify toxic online comments

- End to End NLP Multi label Classification problem
- The Kaggle dataset can be found Here [Click Here](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)

####  Steps to run the project [Click Here](https://github.com/R-aryan/Jigsaw-Toxic-Comment-Classification/blob/main/backend/README.md)

### Dataset Description

We are provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:

- toxic
- severe_toxic
- obscene
- threat
- insult
- identity_hate

The Goal is to  create a model which predicts a probability of each type of toxicity for each comment.


### Following are the screenshots for the output, and the request.

- Request sample 
![Sample request](https://github.com/R-aryan/Jigsaw-Toxic-Comment-Classification/blob/develop/msc/toxic_request.png)
  <br>
  <br>
  
- Response Sample

![Sample response](https://github.com/R-aryan/Jigsaw-Toxic-Comment-Classification/blob/develop/msc/toxic_response.png)


